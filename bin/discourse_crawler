#!/usr/bin/env python

import argparse
import logging
import os
import time

from crawling import DiscourseCrawler

parser = argparse.ArgumentParser(
                    prog = 'discourse_crawler',
                    description = 'Crawls all of the information in a discourse instance')\


parser.add_argument('-d', '--db', required=True, )      # option that takes a value
parser.add_argument('-u', '--url', required=True)
parser.add_argument('-r', '--remove_db', type=bool, default=False, action=argparse.BooleanOptionalAction)

logger = logging.getLogger()
logger.setLevel(logging.INFO)

args = parser.parse_args()
#print(args.db, args.url)

if args.remove_db:
    os.remove(args.db)
c = DiscourseCrawler(args.url, "sqlite:///"+args.db)
if args.remove_db:
    c.create_db()
start_time = time.time()
logging.info("Started crawling at "+str(start_time))
c.crawl(echo=False)
end_time = time.time()
logging.info("Finished crawling at "+str(end_time))
logging.info("Elapsed time: "+str(end_time-start_time))
